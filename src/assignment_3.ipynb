{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cab3a8a",
   "metadata": {},
   "source": [
    "# Assignment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcf4ce5",
   "metadata": {},
   "source": [
    "This project compares three feedforward neural network training algorithms: Stochastic Gradient Descent (SGD), Scaled Conjugate Gradient (SCG), and LeapFrog. Using six datasets—three for classification and three for regression—the study evaluates convergence speed, stability, and predictive accuracy. Each network has a single hidden layer, with experiments across different hidden layer sizes and hyperparameters. Performance is measured using accuracy and F1-score for classification, and MSE, RMSE, and R² for regression, alongside training time and convergence behavior. The results highlight the strengths and weaknesses of each optimizer across problems of varying complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994246ee",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98d9f7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: appnope==0.1.4 in /Users/tasheelgovender/Desktop/Dev/ML_assignment3/.venv/lib/python3.13/site-packages (from -r requirements.txt (line 1)) (0.1.4)\n",
      "Requirement already satisfied: asttokens==3.0.0 in /Users/tasheelgovender/Desktop/Dev/ML_assignment3/.venv/lib/python3.13/site-packages (from -r requirements.txt (line 2)) (3.0.0)\n",
      "Requirement already satisfied: comm==0.2.3 in /Users/tasheelgovender/Desktop/Dev/ML_assignment3/.venv/lib/python3.13/site-packages (from -r requirements.txt (line 3)) (0.2.3)\n",
      "Requirement already satisfied: contourpy==1.3.3 in /Users/tasheelgovender/Desktop/Dev/ML_assignment3/.venv/lib/python3.13/site-packages (from -r requirements.txt (line 4)) (1.3.3)\n",
      "Requirement already satisfied: cycler==0.12.1 in /Users/tasheelgovender/Desktop/Dev/ML_assignment3/.venv/lib/python3.13/site-packages (from -r requirements.txt (line 5)) (0.12.1)\n",
      "Requirement already satisfied: debugpy==1.8.17 in /Users/tasheelgovender/Desktop/Dev/ML_assignment3/.venv/lib/python3.13/site-packages (from -r requirements.txt (line 6)) (1.8.17)\n",
      "Requirement already satisfied: decorator==5.2.1 in /Users/tasheelgovender/Desktop/Dev/ML_assignment3/.venv/lib/python3.13/site-packages (from -r requirements.txt (line 7)) (5.2.1)\n",
      "Requirement already satisfied: executing==2.2.1 in /Users/tasheelgovender/Desktop/Dev/ML_assignment3/.venv/lib/python3.13/site-packages (from -r requirements.txt (line 8)) (2.2.1)\n",
      "Requirement already satisfied: fonttools==4.60.0 in /Users/tasheelgovender/Desktop/Dev/ML_assignment3/.venv/lib/python3.13/site-packages (from -r requirements.txt (line 9)) (4.60.0)\n",
      "Requirement already satisfied: ipykernel==6.30.1 in /Users/tasheelgovender/Desktop/Dev/ML_assignment3/.venv/lib/python3.13/site-packages (from -r requirements.txt (line 10)) (6.30.1)\n",
      "Requirement already satisfied: ipython==9.5.0 in /Users/tasheelgovender/Desktop/Dev/ML_assignment3/.venv/lib/python3.13/site-packages (from -r requirements.txt (line 11)) (9.5.0)\n",
      "Requirement already satisfied: ipython_pygments_lexers==1.1.1 in /Users/tasheelgovender/Desktop/Dev/ML_assignment3/.venv/lib/python3.13/site-packages (from -r requirements.txt (line 12)) (1.1.1)\n",
      "Requirement already satisfied: jedi==0.19.2 in /Users/tasheelgovender/Desktop/Dev/ML_assignment3/.venv/lib/python3.13/site-packages (from -r requirements.txt (line 13)) (0.19.2)\n",
      "Requirement already satisfied: joblib==1.5.2 in /Users/tasheelgovender/Desktop/Dev/ML_assignment3/.venv/lib/python3.13/site-packages (from -r requirements.txt (line 14)) (1.5.2)\n",
      "Requirement already satisfied: jupyter_client==8.6.3 in /Users/tasheelgovender/Desktop/Dev/ML_assignment3/.venv/lib/python3.13/site-packages (from -r requirements.txt (line 15)) (8.6.3)\n",
      "Requirement already satisfied: jupyter_core==5.8.1 in /Users/tasheelgovender/Desktop/Dev/ML_assignment3/.venv/lib/python3.13/site-packages (from -r requirements.txt (line 16)) (5.8.1)\n",
      "Requirement already satisfied: kiwisolver==1.4.9 in /Users/tasheelgovender/Desktop/Dev/ML_assignment3/.venv/lib/python3.13/site-packages (from -r requirements.txt (line 17)) (1.4.9)\n",
      "Requirement already satisfied: matplotlib==3.10.6 in /Users/tasheelgovender/Desktop/Dev/ML_assignment3/.venv/lib/python3.13/site-packages (from -r requirements.txt (line 18)) (3.10.6)\n",
      "Requirement already satisfied: matplotlib-inline==0.1.7 in /Users/tasheelgovender/Desktop/Dev/ML_assignment3/.venv/lib/python3.13/site-packages (from -r requirements.txt (line 19)) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio==1.6.0 in /Users/tasheelgovender/Desktop/Dev/ML_assignment3/.venv/lib/python3.13/site-packages (from -r requirements.txt (line 20)) (1.6.0)\n",
      "Requirement already satisfied: numpy==2.3.3 in /Users/tasheelgovender/Desktop/Dev/ML_assignment3/.venv/lib/python3.13/site-packages (from -r requirements.txt (line 21)) (2.3.3)\n",
      "Requirement already satisfied: packaging==25.0 in /Users/tasheelgovender/Desktop/Dev/ML_assignment3/.venv/lib/python3.13/site-packages (from -r requirements.txt (line 22)) (25.0)\n",
      "Requirement already satisfied: pandas==2.3.2 in /Users/tasheelgovender/Desktop/Dev/ML_assignment3/.venv/lib/python3.13/site-packages (from -r requirements.txt (line 23)) (2.3.2)\n",
      "Requirement already satisfied: parso==0.8.5 in /Users/tasheelgovender/Desktop/Dev/ML_assignment3/.venv/lib/python3.13/site-packages (from -r requirements.txt (line 24)) (0.8.5)\n",
      "Requirement already satisfied: pexpect==4.9.0 in /Users/tasheelgovender/Desktop/Dev/ML_assignment3/.venv/lib/python3.13/site-packages (from -r requirements.txt (line 25)) (4.9.0)\n",
      "Requirement already satisfied: pillow==11.3.0 in /Users/tasheelgovender/Desktop/Dev/ML_assignment3/.venv/lib/python3.13/site-packages (from -r requirements.txt (line 26)) (11.3.0)\n",
      "Requirement already satisfied: platformdirs==4.4.0 in /Users/tasheelgovender/Desktop/Dev/ML_assignment3/.venv/lib/python3.13/site-packages (from -r requirements.txt (line 27)) (4.4.0)\n",
      "Requirement already satisfied: prompt_toolkit==3.0.52 in /Users/tasheelgovender/Desktop/Dev/ML_assignment3/.venv/lib/python3.13/site-packages (from -r requirements.txt (line 28)) (3.0.52)\n",
      "Requirement already satisfied: psutil==7.1.0 in /Users/tasheelgovender/Desktop/Dev/ML_assignment3/.venv/lib/python3.13/site-packages (from -r requirements.txt (line 29)) (7.1.0)\n",
      "Requirement already satisfied: ptyprocess==0.7.0 in /Users/tasheelgovender/Desktop/Dev/ML_assignment3/.venv/lib/python3.13/site-packages (from -r requirements.txt (line 30)) (0.7.0)\n",
      "Requirement already satisfied: pure_eval==0.2.3 in /Users/tasheelgovender/Desktop/Dev/ML_assignment3/.venv/lib/python3.13/site-packages (from -r requirements.txt (line 31)) (0.2.3)\n",
      "Requirement already satisfied: Pygments==2.19.2 in /Users/tasheelgovender/Desktop/Dev/ML_assignment3/.venv/lib/python3.13/site-packages (from -r requirements.txt (line 32)) (2.19.2)\n",
      "Requirement already satisfied: pyparsing==3.2.5 in /Users/tasheelgovender/Desktop/Dev/ML_assignment3/.venv/lib/python3.13/site-packages (from -r requirements.txt (line 33)) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil==2.9.0.post0 in /Users/tasheelgovender/Desktop/Dev/ML_assignment3/.venv/lib/python3.13/site-packages (from -r requirements.txt (line 34)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz==2025.2 in /Users/tasheelgovender/Desktop/Dev/ML_assignment3/.venv/lib/python3.13/site-packages (from -r requirements.txt (line 35)) (2025.2)\n",
      "Requirement already satisfied: pyzmq==27.1.0 in /Users/tasheelgovender/Desktop/Dev/ML_assignment3/.venv/lib/python3.13/site-packages (from -r requirements.txt (line 36)) (27.1.0)\n",
      "Requirement already satisfied: scikit-learn==1.7.2 in /Users/tasheelgovender/Desktop/Dev/ML_assignment3/.venv/lib/python3.13/site-packages (from -r requirements.txt (line 37)) (1.7.2)\n",
      "Requirement already satisfied: scipy==1.16.2 in /Users/tasheelgovender/Desktop/Dev/ML_assignment3/.venv/lib/python3.13/site-packages (from -r requirements.txt (line 38)) (1.16.2)\n",
      "Requirement already satisfied: seaborn==0.13.2 in /Users/tasheelgovender/Desktop/Dev/ML_assignment3/.venv/lib/python3.13/site-packages (from -r requirements.txt (line 39)) (0.13.2)\n",
      "Requirement already satisfied: six==1.17.0 in /Users/tasheelgovender/Desktop/Dev/ML_assignment3/.venv/lib/python3.13/site-packages (from -r requirements.txt (line 40)) (1.17.0)\n",
      "Requirement already satisfied: stack-data==0.6.3 in /Users/tasheelgovender/Desktop/Dev/ML_assignment3/.venv/lib/python3.13/site-packages (from -r requirements.txt (line 41)) (0.6.3)\n",
      "Requirement already satisfied: threadpoolctl==3.6.0 in /Users/tasheelgovender/Desktop/Dev/ML_assignment3/.venv/lib/python3.13/site-packages (from -r requirements.txt (line 42)) (3.6.0)\n",
      "Requirement already satisfied: tornado==6.5.2 in /Users/tasheelgovender/Desktop/Dev/ML_assignment3/.venv/lib/python3.13/site-packages (from -r requirements.txt (line 43)) (6.5.2)\n",
      "Requirement already satisfied: traitlets==5.14.3 in /Users/tasheelgovender/Desktop/Dev/ML_assignment3/.venv/lib/python3.13/site-packages (from -r requirements.txt (line 44)) (5.14.3)\n",
      "Requirement already satisfied: tzdata==2025.2 in /Users/tasheelgovender/Desktop/Dev/ML_assignment3/.venv/lib/python3.13/site-packages (from -r requirements.txt (line 45)) (2025.2)\n",
      "Requirement already satisfied: wcwidth==0.2.14 in /Users/tasheelgovender/Desktop/Dev/ML_assignment3/.venv/lib/python3.13/site-packages (from -r requirements.txt (line 46)) (0.2.14)\n"
     ]
    }
   ],
   "source": [
    "! pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "72ddc923",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.datasets import load_iris\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from typing import List, Tuple, Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8979ee4b",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52652ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width  petal_length  petal_width species\n",
      "0           5.1          3.5           1.4          0.2  setosa\n",
      "1           4.9          3.0           1.4          0.2  setosa\n",
      "2           4.7          3.2           1.3          0.2  setosa\n",
      "3           4.6          3.1           1.5          0.2  setosa\n",
      "4           5.0          3.6           1.4          0.2  setosa\n"
     ]
    }
   ],
   "source": [
    "# Iris Dataset\n",
    "iris = sns.load_dataset(\"iris\")\n",
    "print(iris.head())\n",
    "\n",
    "X = iris.drop(\"species\", axis=1)\n",
    "y = iris[\"species\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0d742d",
   "metadata": {},
   "source": [
    "### Function approx."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b257fa5",
   "metadata": {},
   "source": [
    "## Pre Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5905aa",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae39e7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iris Dataset\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686c9c94",
   "metadata": {},
   "source": [
    "### Function Approx."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11210285",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "782a2018",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedforwardNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, activation_fn=nn.ReLU):\n",
    "        super(FeedforwardNN, self).__init__()\n",
    "        self.hidden = nn.Linear(input_dim, hidden_dim)\n",
    "        self.activation = activation_fn()\n",
    "        self.output = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.hidden(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd77059e",
   "metadata": {},
   "source": [
    "### Training Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ffd22c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD Training Function\n",
    "def train_sgd(model, X_train, y_train, X_test, y_test, epochs=50, lr=0.01, batch_size=32):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "    dataset = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for xb, yb in loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(xb)\n",
    "            loss = criterion(outputs, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * xb.size(0)\n",
    "        train_loss = running_loss / len(loader.dataset)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # Evaluate on test set\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(X_test_tensor)\n",
    "            loss = criterion(outputs, y_test_tensor)\n",
    "            test_losses.append(loss.item())\n",
    "\n",
    "    return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d5b7052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Losses: [1.1124460776646932, 1.0765247583389281, 1.04386301835378, 1.0144209702809652, 0.9876567800839742, 0.9623398423194885, 0.9400183161099752, 0.9194311340649922, 0.9003729701042176, 0.8827384432156881, 0.8662549535433451, 0.8513033986091614, 0.837253475189209, 0.8241028110186259, 0.8117499510447185, 0.7997944355010986, 0.7890545566876729, 0.7787570675214132, 0.7689792116483053, 0.7597044746081034, 0.7508195241292318, 0.7420593738555908, 0.7340576489766438, 0.726137085755666, 0.7183952450752258, 0.7110705574353536, 0.7041035016377767, 0.6971396883328755, 0.6904532392819722, 0.6839908321698507, 0.6777046680450439, 0.6715979139010112, 0.6656497041384379, 0.6597405234972636, 0.6540937701861064, 0.64858078956604, 0.6431231141090393, 0.6379727005958558, 0.632970949014028, 0.6280665834744771, 0.6230239272117615, 0.6182572523752848, 0.6136135737101237, 0.6090578039487203, 0.6047172824541728, 0.6004226088523865, 0.5961479902267456, 0.5919347723325094, 0.5878912289937337, 0.5840573946634928]\n",
      "Test Losses: [1.063238501548767, 1.0307942628860474, 1.001689076423645, 0.9743272662162781, 0.9487033486366272, 0.9260156154632568, 0.9052059054374695, 0.8853620886802673, 0.8672567009925842, 0.8499071002006531, 0.8339583277702332, 0.819347083568573, 0.8052631616592407, 0.7918981313705444, 0.7791023850440979, 0.767182469367981, 0.7560072541236877, 0.7452852129936218, 0.7353424429893494, 0.725462019443512, 0.7160254120826721, 0.7069259285926819, 0.6983267664909363, 0.6895896792411804, 0.6813940405845642, 0.67359459400177, 0.6658168435096741, 0.6583607792854309, 0.650985836982727, 0.6439126133918762, 0.6369706988334656, 0.6302403807640076, 0.6236472725868225, 0.6171716451644897, 0.6108962893486023, 0.6047857403755188, 0.5988666415214539, 0.5931262969970703, 0.5876820683479309, 0.5822800993919373, 0.5768079161643982, 0.5715228915214539, 0.5664398670196533, 0.5614632964134216, 0.5565131306648254, 0.5518671870231628, 0.5471946597099304, 0.5425339937210083, 0.538044273853302, 0.5338436365127563]\n"
     ]
    }
   ],
   "source": [
    "model = FeedforwardNN(input_dim=4, hidden_dim=16, output_dim=3)\n",
    "train_losses, test_losses = train_sgd(model, X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "print(\"Train Losses:\", train_losses)\n",
    "print(\"Test Losses:\", test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "48aa3547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCG Training Function\n",
    "def train_scg(\n",
    "    model: nn.Module,\n",
    "    X_train: torch.Tensor,\n",
    "    y_train: torch.Tensor,\n",
    "    X_test: torch.Tensor,\n",
    "    y_test: torch.Tensor,\n",
    "    max_epochs: int = 1000,\n",
    "    tolerance: float = 1e-6,\n",
    "    sigma: float = 5e-5,\n",
    "    lambda_init: float = 5e-7,\n",
    "    verbose: bool = True,\n",
    "    eval_freq: int = 10\n",
    ") -> Tuple[List[float], List[float]]:\n",
    "    \"\"\"\n",
    "    Train a PyTorch neural network using Scaled Conjugate Gradient algorithm.\n",
    "    \n",
    "    Args:\n",
    "        model: PyTorch neural network model\n",
    "        X_train: Training input data\n",
    "        y_train: Training target data\n",
    "        X_test: Test input data  \n",
    "        y_test: Test target data\n",
    "        max_epochs: Maximum number of training epochs\n",
    "        tolerance: Convergence tolerance for gradient norm\n",
    "        sigma: Parameter for Hessian approximation\n",
    "        lambda_init: Initial regularization parameter\n",
    "        verbose: Whether to print progress\n",
    "        eval_freq: Frequency of evaluation and printing\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (train_losses, test_losses)\n",
    "    \"\"\"\n",
    "    \n",
    "    device = next(model.parameters()).device\n",
    "    X_train = X_train.to(device)\n",
    "    y_train = y_train.to(device)\n",
    "    X_test = X_test.to(device)\n",
    "    y_test = y_test.to(device)\n",
    "    \n",
    "    # Determine loss function based on model output\n",
    "    if y_train.dtype == torch.long or (y_train.ndim == 1 and len(torch.unique(y_train)) <= 10):\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        task_type = 'classification'\n",
    "    else:\n",
    "        criterion = nn.MSELoss()\n",
    "        task_type = 'regression'\n",
    "    \n",
    "    # Get total number of parameters\n",
    "    n_params = sum(p.numel() for p in model.parameters())\n",
    "    \n",
    "    # Helper functions\n",
    "    def get_weights():\n",
    "        \"\"\"Extract all model parameters as a single vector\"\"\"\n",
    "        return torch.cat([p.view(-1) for p in model.parameters()])\n",
    "    \n",
    "    def set_weights(weights):\n",
    "        \"\"\"Set model parameters from a single vector\"\"\"\n",
    "        idx = 0\n",
    "        for p in model.parameters():\n",
    "            param_length = p.numel()\n",
    "            p.data = weights[idx:idx + param_length].view(p.shape)\n",
    "            idx += param_length\n",
    "    \n",
    "    def compute_loss_and_gradient(weights):\n",
    "        \"\"\"Compute loss and gradient for given weights\"\"\"\n",
    "        set_weights(weights)\n",
    "        model.zero_grad()\n",
    "        \n",
    "        outputs = model(X_train)\n",
    "        if task_type == 'classification':\n",
    "            loss = criterion(outputs, y_train)\n",
    "        else:\n",
    "            loss = criterion(outputs, y_train)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        # Extract gradients\n",
    "        grad = torch.cat([p.grad.view(-1) for p in model.parameters()])\n",
    "        \n",
    "        return loss.item(), grad\n",
    "    \n",
    "    def evaluate_model():\n",
    "        \"\"\"Evaluate model on train and test sets\"\"\"\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            # Training loss\n",
    "            train_outputs = model(X_train)\n",
    "            if task_type == 'classification':\n",
    "                train_loss = criterion(train_outputs, y_train).item()\n",
    "            else:\n",
    "                train_loss = criterion(train_outputs, y_train).item()\n",
    "            \n",
    "            # Test loss\n",
    "            test_outputs = model(X_test)\n",
    "            if task_type == 'classification':\n",
    "                test_loss = criterion(test_outputs, y_test).item()\n",
    "            else:\n",
    "                test_loss = criterion(test_outputs, y_test).item()\n",
    "        \n",
    "        model.train()\n",
    "        return train_loss, test_loss\n",
    "    \n",
    "    # Initialize SCG variables\n",
    "    w_k = get_weights()\n",
    "    f_k, g_k = compute_loss_and_gradient(w_k)\n",
    "    r_k = g_k.clone()\n",
    "    r_k_prev = None  # Will store previous gradient for beta calculation\n",
    "    p_k = -r_k.clone()\n",
    "    \n",
    "    lambda_k = lambda_init\n",
    "    lambda_bar = 0.0\n",
    "    success = True\n",
    "    k = 0\n",
    "    \n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    \n",
    "    # Initial evaluation\n",
    "    train_loss, test_loss = evaluate_model()\n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Initial - Train Loss: {train_loss:.6f}, Test Loss: {test_loss:.6f}\")\n",
    "    \n",
    "    # Main SCG loop\n",
    "    for epoch in range(max_epochs):\n",
    "        # Step 1: Calculate scaling parameter if successful step\n",
    "        if success:\n",
    "            sigma_k = sigma / torch.sqrt(torch.dot(p_k, p_k))\n",
    "        \n",
    "        # Step 2: Approximate Hessian-vector product\n",
    "        w_temp = w_k + sigma_k * p_k\n",
    "        _, g_temp = compute_loss_and_gradient(w_temp)\n",
    "        s_k = (g_temp - g_k) / sigma_k\n",
    "        \n",
    "        # Step 3 & 4: Scale the search direction\n",
    "        delta_k = torch.dot(p_k, s_k)\n",
    "        \n",
    "        if delta_k <= 0:\n",
    "            s_k = s_k + (lambda_k - delta_k) * p_k\n",
    "            delta_k = lambda_k * torch.dot(p_k, p_k)\n",
    "            lambda_k = 2 * lambda_k\n",
    "        \n",
    "        # Step 5: Calculate step length\n",
    "        mu_k = torch.dot(p_k, r_k)\n",
    "        alpha_k = mu_k / delta_k\n",
    "        \n",
    "        # Step 6: Calculate comparison parameter\n",
    "        Delta_k = -alpha_k * mu_k\n",
    "        \n",
    "        # Step 7: Update weights and evaluate\n",
    "        w_new = w_k + alpha_k * p_k\n",
    "        f_new, _ = compute_loss_and_gradient(w_new)\n",
    "        Delta_f = f_new - f_k\n",
    "        \n",
    "        # Step 8: Test for successful reduction\n",
    "        if Delta_f < 0.25 * Delta_k:\n",
    "            success = True\n",
    "            lambda_bar = 0\n",
    "            \n",
    "            if Delta_f >= 0.75 * Delta_k:\n",
    "                lambda_k = lambda_k / 4\n",
    "            \n",
    "            # Accept the step\n",
    "            w_k = w_new\n",
    "            f_k = f_new\n",
    "            r_k_prev = r_k.clone()  # Store previous gradient\n",
    "            _, g_k = compute_loss_and_gradient(w_k)\n",
    "            r_k = g_k.clone()\n",
    "            lambda_bar = lambda_bar + lambda_k\n",
    "            lambda_k = lambda_bar\n",
    "            \n",
    "        else:\n",
    "            success = False\n",
    "            lambda_bar = lambda_bar + lambda_k\n",
    "            lambda_k = lambda_bar\n",
    "        \n",
    "        # Step 9: Update search direction (only if successful)\n",
    "        if success:\n",
    "            # Check for restart condition\n",
    "            if k % n_params == 0 or r_k_prev is None:\n",
    "                p_k = -r_k.clone()  # Restart with steepest descent\n",
    "            else:\n",
    "                # Polak-Ribiere formula\n",
    "                beta_k = torch.dot(r_k, r_k - r_k_prev) / (torch.dot(r_k_prev, r_k_prev) + 1e-10)\n",
    "                p_k = -r_k + beta_k * p_k\n",
    "            \n",
    "            k += 1\n",
    "            \n",
    "            # Check convergence\n",
    "            grad_norm = torch.norm(r_k).item()\n",
    "            if grad_norm < tolerance:\n",
    "                if verbose:\n",
    "                    print(f\"Converged at epoch {epoch}, gradient norm: {grad_norm:.2e}\")\n",
    "                break\n",
    "            \n",
    "            # Evaluate and store losses\n",
    "            if epoch % eval_freq == 0 or epoch == max_epochs - 1:\n",
    "                train_loss, test_loss = evaluate_model()\n",
    "                train_losses.append(train_loss)\n",
    "                test_losses.append(test_loss)\n",
    "                \n",
    "                if verbose:\n",
    "                    print(f\"Epoch {epoch:4d} - Train Loss: {train_loss:.6f}, \"\n",
    "                          f\"Test Loss: {test_loss:.6f}, Grad Norm: {grad_norm:.2e}\")\n",
    "    \n",
    "    # Final evaluation if not already done\n",
    "    if (max_epochs - 1) % eval_freq != 0:\n",
    "        train_loss, test_loss = evaluate_model()\n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Training completed. Final - Train Loss: {train_losses[-1]:.6f}, \"\n",
    "              f\"Test Loss: {test_losses[-1]:.6f}\")\n",
    "    \n",
    "    return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4de23cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial - Train Loss: 1.319261, Test Loss: 1.270033\n",
      "Training completed. Final - Train Loss: 1.319261, Test Loss: 1.270033\n",
      "Train Losses: [1.3192613124847412]\n",
      "Test Losses: [1.2700326442718506]\n"
     ]
    }
   ],
   "source": [
    "model = FeedforwardNN(input_dim=4, hidden_dim=16, output_dim=3)\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "train_losses, test_losses = train_scg(\n",
    "    model=model,\n",
    "    X_train=X_train_tensor,\n",
    "    y_train=y_train_tensor,\n",
    "    X_test=X_test_tensor,\n",
    "    y_test=y_test_tensor,\n",
    "    max_epochs=500,\n",
    "    tolerance=1e-5,\n",
    "    verbose=True,\n",
    "    eval_freq=1\n",
    ")\n",
    "print(\"Train Losses:\", train_losses)\n",
    "print(\"Test Losses:\", test_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef9d413",
   "metadata": {},
   "source": [
    "### Visualisatin and Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591ce1ea",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
